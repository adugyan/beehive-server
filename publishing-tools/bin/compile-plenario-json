#!/usr/bin/env python3
import argparse
import csv
import json
import gzip
import os
from datetime import datetime
from itertools import groupby


def load_csv_file(path):
    with open(path) as file:
        return list(csv.DictReader(file))


def load_data_file(path):
    with gzip.open(path, 'rt') as file:
        reader = csv.DictReader(file)

        for row in reader:
            node_id = row['node_id']

            timestamp = datetime.strptime(row['timestamp'], '%Y/%m/%d %H:%M:%S')

            try:
                value = float(row['value_hrf'])
            except ValueError:
                continue

            sensor = row['sensor']
            parameter = row['parameter']

            yield node_id, timestamp, sensor, parameter, value


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('project_dir', help='Project directory.')
    args = parser.parse_args()

    os.chdir(args.project_dir)

    nodes = load_csv_file('nodes.csv')
    nodes_by_id = {node['node_id']: node for node in nodes}

    results = []

    samples = load_data_file('data.csv.gz')

    for (node_id, timestamp), groupsamples in groupby(samples, key=lambda s: (s[0], s[1])):
        observations = {}

        if node_id not in nodes_by_id:
            continue

        node = nodes_by_id[node_id]

        try:
            lat = float(node['lat'])
        except (KeyError, ValueError):
            continue

        try:
            lon = float(node['lon'])
        except (KeyError, ValueError):
            continue

        for sensor, sensorsamples in groupby(groupsamples, key=lambda s: s[2]):
            observation = {}

            for s in sensorsamples:
                observation[s[3]] = s[4]

            observations[sensor] = observation

        results.append({
            'node_id': node['vsn'],
            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
            'latitude': lat,
            'longitude': lon,
            'human_address': node['address'],
            'observations': observations,
        })

with open('plenario-data.json', 'w') as file:
    json.dump(results, file)
