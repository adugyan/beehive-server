#!/bin/sh

cd $1

# prepare digest dir
mkdir -p digest/metadata

# add latest metadata files
curl https://raw.githubusercontent.com/waggle-sensor/beehive-server/master/publishing-tools/docs/digest-readme.md > digest/README.md
curl https://raw.githubusercontent.com/waggle-sensor/beehive-server/master/publishing-tools/examples/plenario/nodes.csv > digest/metadata/nodes.csv
curl https://raw.githubusercontent.com/waggle-sensor/beehive-server/master/publishing-tools/examples/plenario/sensors.csv > digest/metadata/sensors.csv
tar -zcvf metadata.tar.gz digest/metadata

# combine all data files
zcat staging/*/*.csv.gz | awk 'BEGIN { FS=";"; OFS=","; print "node_id,timestamp,plugin,sensor,parameter,value" } {print $1, $2, $3, $5, $6, $7}' > digest/data.csv
tar -zcvf digest-aot-chicago.tar.gz digest

# prepare per node datasets - can move before all data and combine these,
# but i'll get the output right first.
mkdir -p nodedata

cd staging

for nodeid in $(ls -d *); do
  echo $nodeid
  zcat $nodeid/*.csv.gz | awk 'BEGIN { FS=";"; OFS=","; print "node_id,timestamp,plugin,sensor,parameter,value" } {print $1, $2, $3, $5, $6, $7}' > ../nodedata/$nodeid.csv
done

cd ..
tar -zcvf nodedata.tar.gz nodedata
