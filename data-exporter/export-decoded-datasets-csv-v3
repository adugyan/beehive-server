#!/usr/bin/env python3
from cassandra.cluster import Cluster
import os
import logging
import csv
import binascii
import time
import sys
from waggle.protocol.v3 import unpack_sensors as unpack_sensors_v3
from waggle.protocol.v5 import unpack_sensors as unpack_sensors_v4


def stringify(x):
    if x is None:
        return 'NA'
    if isinstance(x, tuple) or isinstance(x, list):
        return ','.join(map(stringify, x))
    if isinstance(x, bytes) or isinstance(x, bytearray):
        return binascii.hexlify(x).decode()
    if isinstance(x, float):
        return str(round(x, 5))
    if isinstance(x, bool):
        return int(x)
    return str(x)


decoders = {
    ('coresense', '3'): unpack_sensors_v3,
    ('coresense', '4'): unpack_sensors_v4,
    ('status', '0'): unpack_sensors_v4,
    ('image_example', '0'): unpack_sensors_v4,
    ('spl', '0'): unpack_sensors_v4,
}


def decoderow(row):
    plugin = (row.plugin_name, row.plugin_version)

    if plugin not in decoders:
        return {}

    source = binascii.unhexlify(row.data)
    return decoders[plugin](source)


def convertrows(rows, writer):
    for row in rows:
        plugin = (row.plugin_name, row.plugin_version)

        try:
            samples = decoderow(row)
        except KeyboardInterrupt:
            raise
        except Exception as exc:
            logger.exception('failed to decode {} {} {}'.format(node_id, date, row))
            continue

        for sample in samples:
            if sample.timestamp == 0:
                timestamp = row.timestamp.strftime('%Y/%m/%d %H:%M:%S')
            else:
                timestamp = sample.timestamp

            writer.writerow([
                timestamp,
                node_id,
                sample.subsystem,
                sample.sensor,
                sample.parameter,
                stringify(sample.value_raw),
                stringify(sample.value_hrf),
            ])


logger = logging.getLogger('export')
logger.setLevel(logging.INFO)

cluster = Cluster(connect_timeout=30, control_connection_timeout=30)
session = cluster.connect('waggle')

query = 'SELECT timestamp, plugin_name, plugin_version, parameter, data FROM sensor_data_raw WHERE node_id=%s AND date=%s'

lines = sys.stdin.readlines()

opened = set()

for i, line in enumerate(lines):
    try:
        fields = line.split()

        if len(fields) != 3:
            logger.warning('skipping invalid line: {}'.format(line))
            continue

        node_id = fields[0][-12:].lower()
        date = fields[2]
        partition_key = (fields[1], fields[2])

        prefix = 'datasets/3/{}'.format(node_id)
        os.makedirs(prefix, exist_ok=True)
        filename = '{}/{}.csv'.format(prefix, date)

        if filename in opened:
            mode = 'a'
        else:
            mode = 'w'

        opened.add(filename)

        print(filename, mode)

        rows = session.execute(query, partition_key)
        writer = csv.writer(sys.stdout)
        convertrows(rows, writer)

        # with open(filename, mode) as outfile:
        #     writer = csv.writer(outfile)
        #
        #     if outfile.tell() == 0:
        #         writer.writerow([
        #             'timestamp',
        #             'node_id',
        #             'subsystem',
        #             'sensor',
        #             'parameter',
        #             'value_raw',
        #             'value_hrf',
        #         ])
        #
        #     rows = session.execute(query, partition_key)
            # convertrows(rows, writer)
    except KeyboardInterrupt:
        raise
    except Exception as exc:
        logger.exception('Failed to decode row: {}'.format(row))
